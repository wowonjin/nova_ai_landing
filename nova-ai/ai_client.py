from __future__ import annotations

import os
import sys
import base64
from pathlib import Path
from typing import Optional

def _debug(msg: str) -> None:
    if sys.stderr is not None:
        sys.stderr.write(msg + "\n")
        sys.stderr.flush()

from prompt_loader import get_image_instructions_prompt
from backend.oauth_desktop import get_stored_user
from backend.firebase_profile import (
    check_usage_limit,
    increment_ai_usage,
    get_remaining_usage,
    get_plan_limit,
)


MAX_IMAGE_DIM = 2048  # Higher cap to improve recognition


SYSTEM_PROMPT = """
You are generating a minimal Python script for HWP automation.
Use ONLY the following functions:
- insert_text("text")
- insert_enter()
- insert_space()
- insert_small_paragraph()
- insert_equation("hwp_equation_syntax")
- insert_latex_equation("latex_math")
- insert_template("header.hwp|box.hwp|box_white.hwp")
- focus_placeholder("@@@|###")
- insert_box()
- exit_box()
- insert_view_box()
- insert_table(rows, cols, cell_data=[...], align_center=False, exit_after=True)
- set_bold(True/False)
- set_underline(True/False)
- set_table_border_white()
- set_align_right_next_line()
- set_align_justify_next_line()

Return ONLY Python code. No explanations.

ìˆ˜í•™ ë¬¸ì œë¼ê³  íŒë‹¨ë˜ë©´ ì½”ë“œ ë§¨ ìœ„ì— ì•„ëž˜ í•œ ì¤„ì„ ì¶”ê°€í•œë‹¤ ( [CODE] í‘œì‹œëŠ” ì“°ì§€ ë§ ê²ƒ ):
MATH_CHOICES_EQUATION = True
""".strip()

try:
    from dotenv import load_dotenv
except Exception:
    load_dotenv = None


class AIClientError(RuntimeError):
    """Raised when AI client setup or call fails."""


def _load_env() -> None:
    candidates = [
        Path(__file__).resolve().parent / ".env",
        Path.cwd() / ".env",
    ]
    for path in candidates:
        if not path.exists():
            continue
        if load_dotenv is not None:
            load_dotenv(dotenv_path=path)
            break
        # Fallback: minimal .env parsing when python-dotenv is unavailable.
        try:
            for line in path.read_text(encoding="utf-8").splitlines():
                stripped = line.strip()
                if not stripped or stripped.startswith("#") or "=" not in stripped:
                    continue
                key, value = stripped.split("=", 1)
                key = key.strip()
                value = value.strip().strip('"').strip("'")
                if key and key not in os.environ:
                    os.environ[key] = value
        except Exception:
            pass
        break


def _resolve_model(model: Optional[str]) -> str:
    if model:
        return model
    env_model = (
        os.getenv("NOVA_AI_MODEL")
        or os.getenv("GEMINI_MODEL")
        or os.getenv("LITEPRO_MODEL")
    )
    return env_model or "gemini-2.5-flash"


class AIClient:
    def __init__(self, api_key: Optional[str] = None, model: Optional[str] = None, check_usage: bool = True) -> None:
        _load_env()
        self.api_key = api_key or os.getenv("GEMINI_API_KEY")
        if not self.api_key:
            raise AIClientError("GEMINI_API_KEY is missing.")

        try:
            import google.generativeai as genai
        except Exception as exc:
            raise AIClientError("google-generativeai package is not installed.") from exc

        genai.configure(api_key=self.api_key)
        self._genai = genai
        self.model = _resolve_model(model)
        self._check_usage = check_usage

    def _get_user_info(self) -> tuple[str | None, str]:
        """í˜„ìž¬ ì‚¬ìš©ìž ì •ë³´ ë°˜í™˜: (uid, tier)"""
        user = get_stored_user()
        if user and user.get("uid"):
            return user.get("uid"), str(user.get("plan") or user.get("tier") or "free")
        return None, "free"

    def _check_usage_limit(self) -> None:
        """ì‚¬ìš©ëŸ‰ ì œí•œ ì²´í¬"""
        if not self._check_usage:
            return
        
        uid, tier = self._get_user_info()
        if not uid:
            return  # ë¹„ë¡œê·¸ì¸ ìƒíƒœì—ì„œëŠ” ì²´í¬ ì•ˆí•¨
        
        if not check_usage_limit(uid, tier):
            limit = get_plan_limit(tier)
            normalized_tier = str(tier or "free").lower()
            tier_label = {
                "free": "ë¬´ë£Œ",
                "standard": "Plus",
                "plus": "Plus",
                "test": "Plus",
                "pro": "Ultra",
                "ultra": "Ultra",
            }.get(normalized_tier, tier)

            # ì—…ê·¸ë ˆì´ë“œ ì•ˆë‚´ ë©”ì‹œì§€ (ì›” ê¸°ì¤€)
            upgrade_msg = ""
            if normalized_tier == "free":
                upgrade_msg = "\n\nðŸ’¡ Plus í”Œëžœìœ¼ë¡œ ì—…ê·¸ë ˆì´ë“œí•˜ë©´ ì›” 330íšŒê¹Œì§€ ì‚¬ìš© ê°€ëŠ¥!"
            elif normalized_tier in ("plus", "standard", "test"):
                upgrade_msg = "\n\nðŸ’¡ Ultra í”Œëžœìœ¼ë¡œ ì—…ê·¸ë ˆì´ë“œí•˜ë©´ ì›” 2200íšŒê¹Œì§€ ì‚¬ìš© ê°€ëŠ¥!"

            raise AIClientError(
                f"âš ï¸ ì›” ì‚¬ìš©ëŸ‰ í•œë„ ì´ˆê³¼! ({limit}/{limit})\n"
                f"í˜„ìž¬ í”Œëžœ: {tier_label}"
                f"{upgrade_msg}\n\n"
                "nova-ai.workì—ì„œ í”Œëžœì„ ì—…ê·¸ë ˆì´ë“œí•˜ê±°ë‚˜ ê²°ì œ ì£¼ê¸° ì´ˆê¸°í™” í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            )

    def _record_usage(self) -> None:
        """ì‚¬ìš©ëŸ‰ ê¸°ë¡"""
        if not self._check_usage:
            return
        
        uid, tier = self._get_user_info()
        if not uid:
            return
        
        increment_ai_usage(uid)

    def _encode_image_to_base64(self, image_path: str) -> Optional[str]:
        try:
            with open(image_path, "rb") as image_file:
                return base64.b64encode(image_file.read()).decode("utf-8")
        except Exception:
            return None

    def generate_script(self, prompt: str, image_path: Optional[str] = None) -> str:
        if not prompt.strip():
            return ""

        # ì‚¬ìš©ëŸ‰ ì œí•œ ì²´í¬
        self._check_usage_limit()

        try:
            model = self._genai.GenerativeModel(self.model)
            if image_path:
                from PIL import Image  # type: ignore[import-not-found]

                image = Image.open(image_path).convert("RGB")
                max_dim = max(image.size)
                if max_dim > MAX_IMAGE_DIM:
                    scale = MAX_IMAGE_DIM / max_dim
                    new_size = (int(image.size[0] * scale), int(image.size[1] * scale))
                    image = image.resize(new_size, Image.LANCZOS)
                response = model.generate_content([prompt, image])
            else:
                response = model.generate_content(prompt)
            
            # ì‘ë‹µ í…ìŠ¤íŠ¸ ì•ˆì „í•˜ê²Œ ì¶”ì¶œ
            result_text = ""
            try:
                if hasattr(response, "text"):
                    result_text = response.text
                elif hasattr(response, "parts") and response.parts:
                    result_text = "".join(part.text for part in response.parts if hasattr(part, "text"))
                elif hasattr(response, "candidates") and response.candidates:
                    for candidate in response.candidates:
                        if hasattr(candidate, "content") and hasattr(candidate.content, "parts"):
                            for part in candidate.content.parts:
                                if hasattr(part, "text"):
                                    result_text += part.text
            except Exception as text_err:
                _debug(f"[AI Debug] ì‘ë‹µ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {text_err}")
                # ì°¨ë‹¨ ì‚¬ìœ  í™•ì¸
                if hasattr(response, "prompt_feedback"):
                    _debug(f"[AI Debug] Prompt feedback: {response.prompt_feedback}")
                if hasattr(response, "candidates") and response.candidates:
                    for i, c in enumerate(response.candidates):
                        if hasattr(c, "finish_reason"):
                            _debug(f"[AI Debug] Candidate {i} finish_reason: {c.finish_reason}")
                        if hasattr(c, "safety_ratings"):
                            _debug(f"[AI Debug] Candidate {i} safety_ratings: {c.safety_ratings}")
                result_text = ""
            
        except AIClientError:
            raise
        except Exception as exc:
            _debug(f"[AI Debug] generate_content ì˜ˆì™¸: {exc}")
            raise AIClientError(str(exc)) from exc

        if not result_text.strip():
            # ë¹ˆ ê²°ê³¼ì¼ ë•Œ ë””ë²„ê·¸ ì •ë³´ ì¶œë ¥
            _debug(f"[AI Debug] ë¹ˆ ì‘ë‹µ ë°›ìŒ")
            if hasattr(response, "prompt_feedback"):
                _debug(f"[AI Debug] Prompt feedback: {response.prompt_feedback}")
            if hasattr(response, "candidates") and response.candidates:
                for i, c in enumerate(response.candidates):
                    if hasattr(c, "finish_reason"):
                        _debug(f"[AI Debug] Candidate {i} finish_reason: {c.finish_reason}")
                    if hasattr(c, "safety_ratings"):
                        _debug(f"[AI Debug] Candidate {i} safety_ratings: {c.safety_ratings}")
            return ""
        
        # ì„±ê³µ ì‹œ ì‚¬ìš©ëŸ‰ ê¸°ë¡
        self._record_usage()

        return result_text.strip()

    def build_prompt(
        self,
        description: str,
        image_path: Optional[str] = None,
        ocr_text: str = "",
    ) -> str:
        parts = [SYSTEM_PROMPT]
        if image_path:
            instructions = get_image_instructions_prompt()
            if instructions:
                parts.append(instructions)
        if ocr_text:
            parts.append(
                "OCR extracted text (use this to improve accuracy; "
                "verify with the image and fix obvious OCR errors):\n"
                f"{ocr_text}"
            )
        if description:
            parts.append(f"User request: {description}")
        else:
            parts.append("User request: Extract the image content and type it into HWP.")
        return "\n\n".join(parts)

    def generate_script_for_image(
        self, image_path: str, description: str = "", ocr_text: str = ""
    ) -> str:
        prompt = self.build_prompt(description, image_path=image_path, ocr_text=ocr_text)
        return self.generate_script(prompt, image_path=image_path)
